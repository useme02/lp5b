{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4cf5cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jagta\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 32ms/step - accuracy: 0.6957 - loss: 0.5270 - val_accuracy: 0.8664 - val_loss: 0.3122\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8647 - loss: 0.3119\n",
      "Test Loss: 0.31216368079185486\n",
      "Test Accuracy: 0.8663600087165833\n"
     ]
    }
   ],
   "source": [
    "# Movie Sentiment Analysis using Deep Neural Networks on IMDB Dataset\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, Flatten\n",
    "\n",
    "# ===============================\n",
    "# Parameters Setup\n",
    "# ===============================\n",
    "max_words = 10000         # Only consider the top 10,000 most frequent words\n",
    "max_length = 250          # Cut off reviews after 250 words\n",
    "embedding_size = 50       # Dimension of the embedding vector\n",
    "\n",
    "# ===============================\n",
    "# Load IMDB Dataset\n",
    "# ===============================\n",
    "# The IMDB dataset is already preprocessed: each review is encoded as a sequence of word indexes\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_words)\n",
    "\n",
    "# ===============================\n",
    "# Preprocess Input Sequences\n",
    "# ===============================\n",
    "# Pad sequences so that all reviews have the same length\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=max_length)\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=max_length)\n",
    "\n",
    "# ===============================\n",
    "# Build the Model\n",
    "# ===============================\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_words, output_dim=embedding_size, input_length=max_length))  # Embedding Layer\n",
    "model.add(Flatten())                # Flatten the 3D tensor into 2D for Dense layers\n",
    "model.add(Dense(128, activation='relu'))  # Hidden Dense layer\n",
    "model.add(Dropout(0.5))             # Dropout for regularization\n",
    "model.add(Dense(1, activation='sigmoid'))  # Output layer with sigmoid for binary classification\n",
    "\n",
    "# ===============================\n",
    "# Compile the Model\n",
    "# ===============================\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# ===============================\n",
    "# Train the Model\n",
    "# ===============================\n",
    "batch_size = 32\n",
    "epochs = 1   # You can increase epochs for better accuracy\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "# ===============================\n",
    "# Evaluate the Model\n",
    "# ===============================\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
